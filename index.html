<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Object Sorting with ResNet50 Material Analysis</title>
  <!-- Load TensorFlow.js and COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      background-color: #222;
      color: #eee;
      text-align: center;
    }
    #video, #canvas {
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
    }
    #canvas {
      z-index: 10;
    }
  </style>
</head>
<body>
  <!-- Video element for camera stream -->
  <video id="video" width="640" height="480" autoplay playsinline muted></video>
  <!-- Canvas for overlays (bounding boxes, lines, etc.) -->
  <canvas id="canvas" width="640" height="480"></canvas>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");

    // Fixed positions for the bins.
    const trashBinPos = { x: 50, y: canvas.height - 50 };
    const recycleBinPos = { x: canvas.width - 50, y: canvas.height - 50 };

    // Define which materials are considered recyclable.
    const recyclableMaterials = ["plastic", "metal", "glass", "paper"];

    // Global variables for our models.
    let cocoModel;           // For object detection
    let materialClassifier;  // Your ResNet50-based material classification model

    // Load your trained ResNet50 model (make sure it has been converted to TFJS format)
    tf.loadLayersModel("model/model.json")
      .then(model => {
        materialClassifier = model;
        console.log("Material classifier (ResNet50) loaded.");
      })
      .catch(err => console.error("Error loading material classifier:", err));

    // Start the webcam video stream.
    function startVideoStream() {
      if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: true })
          .then(stream => { video.srcObject = stream; })
          .catch(err => { console.error("Error accessing webcam:", err); });
      } else {
        alert("getUserMedia is not supported by your browser.");
      }
    }

    // Draw the fixed bins.
    function drawBins() {
      // Draw Trash bin (left)
      context.fillStyle = "gray";
      context.beginPath();
      context.arc(trashBinPos.x, trashBinPos.y, 30, 0, 2 * Math.PI);
      context.fill();
      context.font = "16px Arial";
      context.fillStyle = "white";
      context.fillText("Trash", trashBinPos.x - 20, trashBinPos.y + 5);

      // Draw Recycling bin (right)
      context.fillStyle = "blue";
      context.beginPath();
      context.arc(recycleBinPos.x, recycleBinPos.y, 30, 0, 2 * Math.PI);
      context.fill();
      context.fillStyle = "white";
      context.fillText("Recycle", recycleBinPos.x - 30, recycleBinPos.y + 5);
    }

    // Asynchronously classify material using the ResNet50 model.
    async function classifyMaterial(imageData) {
      // Convert the ImageData to a tensor.
      let tensor = tf.browser.fromPixels(imageData);
      // Resize tensor to match the model's expected input (384x384 in this case).
      tensor = tf.image.resizeBilinear(tensor, [384, 384]);
      // Expand dimensions to create a batch (resulting tensor shape becomes [1, 384, 384, 3]).
      tensor = tensor.expandDims(0);
      // Normalize pixel values to the range [0, 1].
      tensor = tensor.toFloat().div(tf.scalar(255));
      
      // Run the model prediction if it has been successfully loaded.
      if (materialClassifier) {
        const prediction = materialClassifier.predict(tensor);
        // Get the predicted class index.
        const predictedIndex = prediction.argMax(-1).dataSync()[0];
        // Map the index to a material label. Adjust the ordering as per your training labels.
        const labels = ["plastic", "metal", "glass", "paper", "organic", "other"];
        return labels[predictedIndex];
      } else {
        return "unknown";
      }
    }


    // Main loop: detect objects, classify material, and draw overlays.
    async function predictWebcam() {
      // Draw the current video frame.
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      drawBins();

      // Run COCO-SSD object detection.
      const predictions = await cocoModel.detect(video);
      // Filter out detections for persons.
      const nonPersonPredictions = predictions.filter(pred => pred.class !== "person");

      // Draw bounding boxes and labels for non-person objects.
      nonPersonPredictions.forEach(prediction => {
        context.strokeStyle = "#00FFFF";
        context.lineWidth = 2;
        context.strokeRect(...prediction.bbox);

        context.font = "16px Arial";
        context.fillStyle = "#00FFFF";
        const labelText = `${prediction.class} ${(prediction.score * 100).toFixed(1)}%`;
        context.fillText(labelText, prediction.bbox[0], (prediction.bbox[1] > 20 ? prediction.bbox[1] - 5 : 20));
      });

      // If there is at least one non-person object, use the first one for material analysis.
      if (nonPersonPredictions.length > 0) {
        const obj = nonPersonPredictions[0];
        // Extract the bounding box (ensure coordinates are valid integers within the canvas boundaries).
        const x = Math.max(0, Math.floor(obj.bbox[0]));
        const y = Math.max(0, Math.floor(obj.bbox[1]));
        const width = Math.floor(obj.bbox[2]);
        const height = Math.floor(obj.bbox[3]);

        let objImageData;
        try {
          objImageData = context.getImageData(x, y, width, height);
        } catch (e) {
          console.error("Error extracting image data:", e);
        }

        if (objImageData) {
          // Run material classification.
          const material = await classifyMaterial(objImageData);
          console.log("Predicted material:", material);

          // Decide the target bin based on material.
          const target = recyclableMaterials.includes(material)
                            ? recycleBinPos
                            : trashBinPos;

          // Calculate center of the object's bounding box.
          const centerX = x + width / 2;
          const centerY = y + height / 2;

          // Draw a red line from the object's center to the target bin.
          context.strokeStyle = "red";
          context.lineWidth = 3;
          context.beginPath();
          context.moveTo(centerX, centerY);
          context.lineTo(target.x, target.y);
          context.stroke();

          // Optionally, display the predicted material above the bounding box.
          context.font = "18px Arial";
          context.fillStyle = "red";
          context.fillText(material, x, (y > 20 ? y - 5 : 20));
        }
      }
      // Continue the loop.
      requestAnimationFrame(predictWebcam);
    }

    // Load the COCO-SSD object detection model.
    cocoSsd.load().then(model => {
      cocoModel = model;
      console.log("COCO-SSD model loaded.");
      video.addEventListener("loadeddata", predictWebcam);
    });

    // Start the video stream on page load.
    startVideoStream();
  </script>
</body>
</html>
