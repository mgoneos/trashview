<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Object Sorting with ResNet50 Material Analysis</title>
  <!-- Load TensorFlow.js and COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      background-color: #222;
      color: #eee;
      text-align: center;
    }
    #video, #canvas {
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
    }
    #canvas {
      z-index: 10;
    }
  </style>
</head>
<body>
  <!-- Video element for camera stream -->
  <video id="video" width="640" height="480" autoplay playsinline muted></video>
  <!-- Canvas for overlays (for the bins and the red line) -->
  <canvas id="canvas" width="640" height="480"></canvas>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");

    // Fixed positions for bins.
    const trashBinPos = { x: 50, y: canvas.height - 50 };
    const recycleBinPos = { x: canvas.width - 50, y: canvas.height - 50 };

    // Define recyclable materials.
    const recyclableMaterials = ["plastic", "metal", "glass", "paper"];

    // Global model variables.
    let cocoModel;           // For object detection.
    let materialClassifier;  // Your ResNet50-based material classification model.

    // Load your ResNet50 model (make sure it is converted to TFJS format and placed in the model folder).
    tf.loadLayersModel("model/model.json")
      .then(model => {
        materialClassifier = model;
        console.log("Material classifier (ResNet50) loaded.");
      })
      .catch(err => console.error("Error loading material classifier:", err));

    // Start the webcam stream.
    function startVideoStream() {
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: true })
          .then(stream => {
            video.srcObject = stream;
          })
          .catch(err => console.error("Error accessing webcam:", err));
      } else {
        alert("getUserMedia is not supported by your browser.");
      }
    }

    // Draw the fixed bins.
    function drawBins() {
      // Draw Trash bin.
      context.fillStyle = "gray";
      context.beginPath();
      context.arc(trashBinPos.x, trashBinPos.y, 30, 0, 2 * Math.PI);
      context.fill();
      context.font = "16px Arial";
      context.fillStyle = "white";
      context.fillText("Trash", trashBinPos.x - 20, trashBinPos.y + 5);

      // Draw Recycling bin.
      context.fillStyle = "blue";
      context.beginPath();
      context.arc(recycleBinPos.x, recycleBinPos.y, 30, 0, 2 * Math.PI);
      context.fill();
      context.fillStyle = "white";
      context.fillText("Recycle", recycleBinPos.x - 30, recycleBinPos.y + 5);
    }

    // Asynchronously classify material using your ResNet50 model.
    async function classifyMaterial(imageData) {
      // Convert the region (ImageData) to a tensor.
      let tensor = tf.browser.fromPixels(imageData);
      // Resize to match your model's expected input (update to 384x384 here if your model expects that).
      tensor = tf.image.resizeBilinear(tensor, [384, 384]);
      // Create a batch dimension.
      tensor = tensor.expandDims(0);
      // Normalize pixel values to [0, 1].
      tensor = tensor.toFloat().div(tf.scalar(255));

      if (materialClassifier) {
        const prediction = materialClassifier.predict(tensor);
        // Retrieve the predicted class index.
        const predictedIndex = prediction.argMax(-1).dataSync()[0];
        // Map the index to material labels. Adjust this list to match your training.
        const labels = ["plastic", "metal", "glass", "paper", "organic", "other"];
        return labels[predictedIndex];
      } else {
        return "unknown";
      }
    }

    // Main loop: detect objects, classify material, and draw overlays.
    async function predictWebcam() {
      // Draw current video frame on canvas.
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      // Draw the bin areas.
      drawBins();

      // Run COCO-SSD object detection.
      const predictions = await cocoModel.detect(video);
      // Filter out 'person' detections.
      const nonPersonPredictions = predictions.filter(pred => pred.class !== "person");

      // If there is at least one non-person object, run material analysis.
      if (nonPersonPredictions.length > 0) {
        const obj = nonPersonPredictions[0];
        // Extract the bounding box (with valid coordinates).
        const x = Math.max(0, Math.floor(obj.bbox[0]));
        const y = Math.max(0, Math.floor(obj.bbox[1]));
        const width = Math.floor(obj.bbox[2]);
        const height = Math.floor(obj.bbox[3]);

        let objImageData;
        try {
          objImageData = context.getImageData(x, y, width, height);
        } catch (e) {
          console.error("Error extracting image data:", e);
        }

        if (objImageData) {
          // Run the material classifier.
          const material = await classifyMaterial(objImageData);
          console.log("Predicted material:", material);

          // Determine the target bin.
          const target = recyclableMaterials.includes(material)
                            ? recycleBinPos
                            : trashBinPos;

          // Calculate the center of the detected object's bounding box.
          const centerX = x + width / 2;
          const centerY = y + height / 2;

          // Draw a red line from the object's center to the target bin.
          context.strokeStyle = "red";
          context.lineWidth = 3;
          context.beginPath();
          context.moveTo(centerX, centerY);
          context.lineTo(target.x, target.y);
          context.stroke();

          // Optionally display the predicted material above the bounding box.
          context.font = "18px Arial";
          context.fillStyle = "red";
          context.fillText(material, x, (y > 20 ? y - 5 : 20));
        }
      }
      requestAnimationFrame(predictWebcam);
    }

    // Load the COCO-SSD model.
    cocoSsd.load().then(model => {
      cocoModel = model;
      console.log("COCO-SSD model loaded.");
      video.addEventListener("loadeddata", predictWebcam);
    });

    // Start the video stream.
    startVideoStream();
  </script>
</body>
</html>
